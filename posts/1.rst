.. title: Deploying a static website on S3 with an SSL certificate using the AWS DevOps tools
.. slug: static-s3-cloudformation
.. date: 2018-07-10
.. tags: aws, s3, static, cloudformation, devops, cloudfront, blog, beginner, tutorial
.. author: Jonathan Pelletier
.. description: tutorial on how to deploy a static website using an AWS S3 bucket with an SSL certificate
.. category: technology

.. figure:: /images/blog_static_website_main_image.png
   :target: /images/blog_static_website_main_image.png
   :class: thumbnail
   :alt: Deploying a static website DevOps style

AWS S3 makes it really easy to host a website composed entirely of static 
assets. This is especially well suited for hosting the output of static 
website generators such as `jekyll <https://jekyllrb.com/>`_, 
`nikola <https://getnikola.com/>`_ or `gatsby <https://www.gatsbyjs.org/>`_. 

In this tutorial, I will show you how you can deploy your static website on S3 
with an SSL certificate created in AWS Certificate Manager. I will be using this 
blog as a use case and show you how you can leverage AWS tools such as 
CloudFormation and CodeBuild to completely automate the 
deployment of new content to your production environment.

Objective and tasks breakdown
-----------------------------
Our objective at the end of this tutorial will be to have our end users access 
a static website using https. We will also want fully automated deployments of new 
content, so that publishing is triggered by a simple commit and push to a github repository where our blog source is hosted. 
We will break down the tasks of this tutorial in 3 parts:

1. Prerequisite.
2. Infrastructure.
3. DevOps.

In the Prerequisite section, we will focus on obtaining a certificate for
our website from AWS Certificate Manager.

In the Infrastructure section, we will present the architecture required to
support our static website. We will be using a CloudFormation template
to specify resources and deploy our website.

Finally, in the DevOps section, we will create a build project that 
automatically triggers an update of our website upon a commit and push to our source code repository on github.

The CloudFormation templates used in this tutorial are all available on the
`github repository of this blog <https://github.com/magnus1984/hedgenet.info.git>`_.

Prerequisite
------------
`https <https://en.wikipedia.org/wiki/HTTPS>`_ requires you to have a certificate issued by a certificate 
authority in order to operate properly. Here, we will be requesting a certificate from
AWS Certificate Manager for a domain name that we already own and manage in AWS Route 53. 

In order to get a certificate, we will need to prove that we own the domain.
We do this by showing Certificate Manager we have control over the resource. 
AWS Certificate Manager allows you to prove control in two ways:

1. Email verification.
2. DNS verification.

In this post, we will use DNS verification.

How does DNS verification works ?
+++++++++++++++++++++++++++++++++
Assuming you own the domain name `hedgenet.info <https://hedgenet.info/>`_, and would like to have a 
certificate for mysubdomain.hedgenet.info. Certificate Manager will require you 
to create records in AWS Route 53 that will proove that you have control over mysubdomain.hedgenet.info.
Here is a picture showing what we need to do:

.. figure:: /images/dns_validation.png
   :target: /images/dns_validation.png
   :class: thumbnail
   :alt: CNAME records to create

   CNAME records to create in Route 53.

Certificate Manager will expect to be able to read these values and will confirm that
you are indeed custodian of the domain in the certificate request.

Once you understand how verification operates, you can easily 
carry out the required steps through the AWS console. I will briefly mentions the steps 
required to have our certificate issued:

1. go to the AWS Certificate Manager console `here <https://console.aws.amazon.com/acm>`_.
2. click on *request a certificate* and select request a public certificate.
3. add the domain names for which you need a certificate.
4. download the .csv file generated by Certificate Manager; it contains the records you will have to create in Route 53.
5. head over to `AWS Route 53 <https://console.aws.amazon.com/route53>`_ and create the CNAME found in your .csv file.

Once you are done, allow a few minutes for Certificate Manager to verify your
domain ownership. I have done this in my AWS account for the domain hedgenet.info. What
you end up with at the end of the verification process should look like this:

.. figure:: /images/hedgenet_certificate.png
   :target: /images/hedgenet_certificate.png
   :class: thumbnail
   :alt: Certificate Manager and a Verified Domain

   Certificate Manager after a successful issuance.

With our certificate in hand, we can now move on to a discussion about the
necessary infrastructure components for our website and how to deploy it.

Infrastructure
--------------
To allow users to access our site with http (notice, no s at the end), we would only need an S3 bucket and
a bit of Route 53 config for our hosting architecture. But, to serve our content over
https, we will require the use of `AWS CloudFront <https://console.aws.amazon.com>`_ amazon's global `content delivery network <https://en.wikipedia.org/wiki/Content_delivery_network>`_.
Here is a simple diagram of our target architecture:

.. figure:: /images/arch_s3_website.png
   :target: /images/arch_s3_website.png
   :class: thumbnail
   :alt: The tutorial Architecture

   The static website architecture we will deploy.

Our endusers will access our website by typing https://hedgenet.info in the address bar of their browser. 
The browser will end up making a request to AWS Route 53, which will point to a CloudFront distribution. The 
distribution will be configured to use our previously created certificate and 
will serve the static content from an S3 bucket.

Since we want to deploy automatically, we will want to use a CloudFormation
template in order to specify our resources and how they interact with each 
other. 

I have written a template that formally defines our architecture. I will leave you a moment to `take a look at it here <https://github.com/magnus1984/hedgenet.info/blob/master/infrastructure/infra.yaml>`_

Writing CloudFormation template may seem tedious 
and overwhelming, but you should always remember that, at it's core, it is 
really just a matter of knowing the resources you need, having 
the documentation nearby and turning the crank patiently. I actually love the fact that CloudFormation forces me to turn a vague idea encoded in a diagram into
a production ready architecture.

Anyways, once you feel like you have a grasp of what's going on in the template, you can start considering deployment.

Deploying the infrastructure
++++++++++++++++++++++++++++
For our blogging use case, we expect the architecture to be very stable. Moreover, we will
only have 1 environment (production). We will therefore deploy our architecture ourselves using the aws cli instead of using something more complicated 
like `AWS CodePipeline <https://console.aws.amazon.com/codepipeline>`_. Here is how I deploy the infrastructure for this website:

.. code-block:: bash

   git https://github.com/magnus1984/hedgenet.info.git
   cd hedgenet.info/infrastructure
   aws cloudformation create-stack --stack-name hedgenetinfo-prod --template-body file://infra.yaml --parameters ParameterKey=DomainName,ParameterValue=hedgenet.info \
   ParameterKey=CertificateArn,ParameterValue=<MY_CERTIFICATE-ARN>

You need to allow some time for the architecture to deploy properly. I have found while testing that a CloudFront distribution
can take on the order of hours to be fully deployed and show the CREATE_COMPLETE status in CloudFormation.

Now that we have the architecture in place, let's move to the DevOps part that we will build using AWS CodeBuild.

DevOps
------
the DevOps pipeline will allow us to automatically deploy our new website content
onto the infrastructure we have specified in our CloudFormation template. Upon a commit
and push to our website repository, we want the following things to happen:

1. build the static assets to be deployed onto the infrastructure.
2. upload the static assets onto the S3 bucket created in the infrastructure.

We can easily achieve this using CodeBuild. 

What is CodeBuild ?
+++++++++++++++++++
At it's core, `AWS CodeBuild <https://console.aws.amazon.com/codebuild>`_ is a service that allows you to specify a set of information concerning 
a machine that will be used to *build* a project. By *build*, we mean applying some kind of operation (e.g: compiling) that
will take an input and return an output at the end. In our case, the blog is a collection of input files written in `Restructured Text <http://docutils.sourceforge.net/rst.html>`_ and the build operation is the parsing of those files to produce another set of files in valid html. 

The information that CodeBuild expects you to specify for a build includes:

1. What operating system is required for your build machine ?
2. What is the *runtime* that you will be using (e.g: Java, Nodejs, Python) ?
3. Where can I find the input of the build ?
4. What is the operation that I should perform on the input ?
5. Where do you want to store the output ?

After you specify that information, CodeBuild is responsible for creating a build server and running instructions that are found
in a file named buildspec.yml each time there is a change in your inpout source. 

In the case of this blog, this is what the build project looks like:

.. figure:: /images/static_codebuild_pipeline.png
   :target: /images/static_codebuild_pipeline.png
   :class: thumbnail
   :alt: CI setup 

   The build project and it's relationship with the Architecture through S3

From the point of view of the blog author, all he has to do is deploy source code revisions to github and the DevOps machinery takes over
the rest until the new content is effectively published.

Using Cloudformation to specify our DevOps artifacts
++++++++++++++++++++++++++++++++++++++++++++++++++++
Just as for our architecture, we will specify our DevOps component using CloudFormation. This allows us to have
everything that is required to operate the blog under one single source code repository, and to deploy everything
automatically.

Again, `I will link here <https://github.com/magnus1984/hedgenet.info/blob/master/devops/pipeline.yaml>`_ to the 
template and let you have a look at it. 

The *tricky* part in this template is that you need to create a proper IAM service role for AWS CodeBuild in order to
carry out to action of deploying to the S3 bucket, as shown on the pipeline image above. This means that the role will require
permission to write files to the bucket.

Also noteworthy is our use of environment variables for the build project. As we will see in the next section, we will ask CodeBuild
,via a buildsec file, to upload the static assets to an S3 bucket. Since all servers managed by CodeBuild have a version of the AWS cli packaged,
we can use something like this to deploy:

.. code-block:: bash

    aws s3 sync output $DEPLOYMENT_S3_BUCKET_NAME

Where DEPLOYMENT_S3_BUCKET_NAME is an environment variable of the CodeBuild server that we set through a value in the CloudFormation template. To get the value of
that environment variable, we simply ask the user to provide the bucket name at deploy time by declaring a ProjectName parameter in the template.

We are almost there to a fully automated blog, the only thing that is left to specify is the operation we want CodeBuild to perform for us at each build. This is done
through a buildspec file.

The buildspec file
++++++++++++++++++
When a source change is detected in your repository, CodeBuild will execute commands that it finds in a file named buildspec.yml (by default). A buildspec file
is pretty self explanatory so let's just take a look at it:

.. code-block:: yaml

    version: 0.2

    phases:
        install:
            commands:
                - pip install -r requirements.txt
        build:
            commands:
                - nikola build
        post_build:
            commands:
                - aws s3 sync output s3://${DEPLOYMENT_S3_BUCKET_NAME}

The file specify phases (install, build and post_build) and a command to run at each of these phases. The commands are specific to our chosen blogging solution (Nikola)
and the last phase command uses the aws s3 command to deploy to our S3 bucket.

Deploying the project
+++++++++++++++++++++
This is how I deploy the build project for the blog:

.. code-block:: bash

   git https://github.com/magnus1984/hedgenet.info.git
   cd hedgenet.info/devops
   aws cloudformation create-stack --stack-name hedgenetinfobuild-prod --template-body file://pipeline.yaml --parameters ParameterKey=ProjectName,ParameterValue=hedgenetbuild \
   ParameterKey=GithubCloneUrl,ParameterValue=https://github.com/magnus1984/hedgenet.info.git ParameterKey=DomainName,ParameterValue=hedgenet.info

**IMPORTANT NOTE**: you need to allow AWS CodeBuild to access your repository in github if this is the first time that you create such a pipeline. The easiest way to
do that, is to use the CodeBuild console to create a new project. Choose a public github repo as a source and follow the instructions. Somewhere along the steps, there will be an Oauth workflow asking you to grant authorization to AWS CodeBuild. Note that this needs to be done only once per account, per region you are deploying builds.

Once the project is deployed, new commits to the repo should trigger a build. Here is what a successful build looks like in the AWS console:


.. figure:: /images/build_phases.png
   :target: /images/build_phases.png
   :class: thumbnail
   :alt: Console showing the successful phases of a build


Conclusion
----------
You now know how to deploy a static website using an SSL certificate managed by AWS Certificate Manager.
All of the infrastructure needed to achieve this goal is specified in CloudFormation templates
(including the DevOps pipeline). Publishing new content is simply a matter of pushing changes to
the master branch of your website repository. What you just built makes for a very modern and convenient
way to blog while maintaining total control over everything. Congratulations !

If you have any questions about this blog, feel free to reach out to me at jonathan.pelletier1@gmail.com
